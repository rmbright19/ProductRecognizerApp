{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Canned_Goods_Classification.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n6ecAvsmQp1I"
      },
      "source": [
        "## Canned Goods Classification using Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YnzuZUSvuR-",
        "colab_type": "text"
      },
      "source": [
        "Modified from https://colab.sandbox.google.com/github/tensorflow/examples/blob/master/community/en/flowers_tf_lite.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iBMcobPHdD8O",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NOG3l_MsBO1A",
        "colab": {}
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNC7vV_zMIcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v77rlkCKW0IJ"
      },
      "source": [
        "## Setup Input Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsK1uVsRMVrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/content/drive/My Drive/cans-final-dataset-16-items'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oMiqD0QES5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for d in os.listdir(base_dir):\n",
        "  try:\n",
        "    ims = [f for f in os.listdir(os.path.join(base_dir, d))]\n",
        "    print(d, len(ims))\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z4gTv7ig2vMh"
      },
      "source": [
        "Use `ImageDataGenerator` to rescale the images.\n",
        "\n",
        "Create the train generator and specify where the train dataset directory, image size, batch size.\n",
        "\n",
        "Create the validation generator with similar approach as the train generator with the flow_from_directory() method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aCLb_yV5JfF3",
        "colab": {}
      },
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    validation_split=0.2)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='training')\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tx1L7fxxWA_G",
        "colab": {}
      },
      "source": [
        "for image_batch, label_batch in train_generator:\n",
        "  break\n",
        "image_batch.shape, label_batch.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZrFFcwUb3iK9"
      },
      "source": [
        "Save the labels in a file which will be downloaded later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-QFZIhWs4dsq",
        "colab": {}
      },
      "source": [
        "print (train_generator.class_indices)\n",
        "\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "labels = labels.replace('-', ' ')\n",
        "labels = labels.replace('_', ' ')\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "duxD_UDSOmng",
        "colab": {}
      },
      "source": [
        "!cat labels.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OkH-kazQecHB"
      },
      "source": [
        "## Create the base model from the pre-trained convnets\n",
        "\n",
        "Create the base model from the **MobileNet V2** model developed at Google, and pre-trained on the ImageNet dataset, a large dataset of 1.4M images and 1000 classes of web images.\n",
        "\n",
        "Load the MobileNetV2 from TensorFlow. Since we are using the pretrained model only for feature extraction and will add and train a classification layer specific to our canned goods dataset, we add the argument `include_top=False` to remove the ImageNet classification layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "19IQ2gqneqmS",
        "colab": {}
      },
      "source": [
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                              include_top=False, \n",
        "                                              weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rlx56nQtfe8Y"
      },
      "source": [
        "## Feature extraction\n",
        "Freeze the convolutional base created from the previous step, using it as a feature extractor. Add a classifier on top of the base model and train the top-level classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tts8BbAtRGvk",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wdMRM8YModbk"
      },
      "source": [
        "### Add a classification head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eApvroIyn1K0",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(16, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g0ylJXE_kRLi"
      },
      "source": [
        "### Compile the model\n",
        "\n",
        "You must compile the model before training it.  Since there are multiple classes, use a categorical cross-entropy loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RpR8HdyMhukJ",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I8ARiyMFsgbH",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "krvBumovycVA",
        "colab": {}
      },
      "source": [
        "print('Number of trainable variables = {}'.format(len(model.trainable_variables)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RxvgOYTDSWTx"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "<!-- TODO(markdaoust): delete steps_per_epoch in TensorFlow r1.14/r2.0 -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JsaRFlZ9B6WK",
        "colab": {}
      },
      "source": [
        "epochs = 40\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    steps_per_epoch=len(train_generator), \n",
        "                    epochs=epochs, \n",
        "                    validation_data=val_generator, \n",
        "                    validation_steps=len(val_generator),\n",
        "                    callbacks = [callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hd94CKImf8vi"
      },
      "source": [
        "### Learning curves\n",
        "\n",
        "Let's take a look at the learning curves of the training and validation accuracy/loss when using the MobileNet V2 base model as a fixed feature extractor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "53OTCh3jnbwV",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzalaRnKdlsx",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0R89cM_d79r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMmb1I2kdx_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get a batch of validation images\n",
        "for image_batch, label_batch in val_generator:\n",
        "  break\n",
        "image_batch.shape, label_batch.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuUJ1Zc2d8XC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate (image_batch, label_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs4T8F3jJI-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dct = {}\n",
        "label_lst = labels.split('\\n')\n",
        "for i in range(len(label_lst)):\n",
        "  label_dct[i] = label_lst[i]\n",
        "label_dct\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SxhlwXLeSvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_arr = model.predict(image_batch)\n",
        "preds = [np.argmax(a) for a in pred_arr]\n",
        "y_true = [np.argmax(a) for a in label_batch]\n",
        "incorrect = 0\n",
        "total = 0\n",
        "for p, y, img in zip(preds, y_true, image_batch):\n",
        "#  print(p,y)\n",
        "  total += 1\n",
        "  if p != y:\n",
        "    print(\"Predicted Class:\", label_dct[p])\n",
        "    print(\"Actual Class:\", label_dct[y])\n",
        "#    print(label_dct[p])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    cv2_imshow(img*255)\n",
        "    incorrect += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q5i1Fk5cFl5",
        "colab_type": "text"
      },
      "source": [
        "The images above show that the model has some difficulty with fine-grained differences. For example, it classified all the Campbell's Tomato Soup as Campbell's Chicken Noodle Soup. These cans are nearly identical except for the words \"Tomato\" and \"Chicken Noodle\". Similarly, the model has some trouble with the three kinds of diced tomatoes from WinCo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7YOAy-Ae58i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(tf.math.confusion_matrix(y_true, preds).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ6h3JzAgG-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number incorrect:\", incorrect)\n",
        "print(\"Total items: \", total)\n",
        "print(\"Accuracy: \", str((total-incorrect)*100/total) + '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kRDabW_u1wnv"
      },
      "source": [
        "## Convert to TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hNvMl6CM6lG4"
      },
      "source": [
        "Saved the model using `tf.saved_model.save` and then convert the saved model to a tf lite compatible format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_LZiKVInWNGy",
        "colab": {}
      },
      "source": [
        "saved_model_dir = 'save/cans_model'\n",
        "tf.saved_model.save(model, saved_model_dir)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GE4w-9S410Dk"
      },
      "source": [
        "Download the converted model and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x47uW_lI1DoV",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('model.tflite')\n",
        "files.download('labels.txt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}